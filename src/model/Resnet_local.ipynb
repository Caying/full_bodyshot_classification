{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GnEt5aFOgV_0"
   },
   "source": [
    "# 0. Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18885,
     "status": "ok",
     "timestamp": 1591961320953,
     "user": {
      "displayName": "­김주호[경영학부]",
      "photoUrl": "",
      "userId": "08193182399981168805"
     },
     "user_tz": -540
    },
    "id": "FizAEXBAu8NE",
    "outputId": "8ec833fd-d651-49dc-995c-9e6ffbf65ca2"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c1TTGcM5gV_6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48406,
     "status": "ok",
     "timestamp": 1591961389451,
     "user": {
      "displayName": "­김주호[경영학부]",
      "photoUrl": "",
      "userId": "08193182399981168805"
     },
     "user_tz": -540
    },
    "id": "e2RZQHpzgV_9",
    "outputId": "bd50f3aa-deb5-4885-c45d-48ade025c543"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10374 images belonging to 2 classes.\n",
      "Found 1154 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "train_dir = 'data/train'\n",
    "validation_dir = 'data/valid'\n",
    "test_dir = 'data/test'\n",
    "\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    " #     rotation_range=90,\n",
    "#      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=256,\n",
    "        shuffle = True,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=64,\n",
    "        shuffle = True,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BCCo-yo9qWVz"
   },
   "source": [
    "# 1. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dTFseJDhuN9M"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13529,
     "status": "ok",
     "timestamp": 1591961424717,
     "user": {
      "displayName": "­김주호[경영학부]",
      "photoUrl": "",
      "userId": "08193182399981168805"
     },
     "user_tz": -540
    },
    "id": "e4ZLrZoTqWVz",
    "outputId": "72605669-5936-428b-fc23-41dd61ce813e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gimjuho/opt/anaconda3/lib/python3.7/site-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    }
   ],
   "source": [
    "net = MobileNet(weights='imagenet',include_top=False,pooling='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2521,
     "status": "ok",
     "timestamp": 1591961428935,
     "user": {
      "displayName": "­김주호[경영학부]",
      "photoUrl": "",
      "userId": "08193182399981168805"
     },
     "user_tz": -540
    },
    "id": "6Ci56qv4yHdZ",
    "outputId": "6e054316-093c-4102-a523-12e4fa7fbb56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_224 (Model)   (None, 1024)              3228864   \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 3,229,889\n",
      "Trainable params: 3,208,001\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "model = Sequential()\n",
    "model.add(net)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.trainable =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r7ipY0v7pXYa"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 636321,
     "status": "error",
     "timestamp": 1591879163107,
     "user": {
      "displayName": "­김주호[경영학부]",
      "photoUrl": "",
      "userId": "08193182399981168805"
     },
     "user_tz": -540
    },
    "id": "-VQK-JUDx_T2",
    "outputId": "3b999e7a-b498-44d2-96b0-91d74433d600"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 10 steps, validate for 10 steps\n",
      "Epoch 1/30\n",
      "10/10 [==============================] - 69s 7s/step - loss: 1.9644 - acc: 0.5037 - val_loss: 1.3601 - val_acc: 0.5031\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 73s 7s/step - loss: 1.3567 - acc: 0.5199 - val_loss: 1.3272 - val_acc: 0.5391\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 72s 7s/step - loss: 1.1431 - acc: 0.5602 - val_loss: 1.4813 - val_acc: 0.5516\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 77s 8s/step - loss: 1.1172 - acc: 0.5754 - val_loss: 1.3162 - val_acc: 0.5703\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 73s 7s/step - loss: 1.0603 - acc: 0.5895 - val_loss: 1.3063 - val_acc: 0.5797\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 73s 7s/step - loss: 0.9659 - acc: 0.6083 - val_loss: 1.3134 - val_acc: 0.5953\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 72s 7s/step - loss: 0.9648 - acc: 0.6184 - val_loss: 1.2689 - val_acc: 0.6047\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 68s 7s/step - loss: 0.9311 - acc: 0.6340 - val_loss: 1.3356 - val_acc: 0.6062\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 69s 7s/step - loss: 0.8664 - acc: 0.6508 - val_loss: 1.2099 - val_acc: 0.6250\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 73s 7s/step - loss: 0.8622 - acc: 0.6695 - val_loss: 1.1013 - val_acc: 0.6422\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 69s 7s/step - loss: 0.8146 - acc: 0.6676 - val_loss: 0.9340 - val_acc: 0.6703\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 67s 7s/step - loss: 0.7740 - acc: 0.6840 - val_loss: 0.9864 - val_acc: 0.6625\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 68s 7s/step - loss: 0.8342 - acc: 0.6617 - val_loss: 1.0058 - val_acc: 0.6625\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 67s 7s/step - loss: 0.7772 - acc: 0.6930 - val_loss: 1.0103 - val_acc: 0.6687\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 65s 7s/step - loss: 0.7606 - acc: 0.6911 - val_loss: 1.0064 - val_acc: 0.6734\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 64s 6s/step - loss: 0.7567 - acc: 0.6899 - val_loss: 1.0024 - val_acc: 0.6766\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 67s 7s/step - loss: 0.7614 - acc: 0.6984 - val_loss: 0.9683 - val_acc: 0.6812\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 68s 7s/step - loss: 0.7306 - acc: 0.6977 - val_loss: 0.9403 - val_acc: 0.6875\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 63s 6s/step - loss: 0.7261 - acc: 0.7096 - val_loss: 1.1003 - val_acc: 0.6672\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 69s 7s/step - loss: 0.7159 - acc: 0.7121 - val_loss: 1.1591 - val_acc: 0.6609\n",
      "Epoch 21/30\n",
      " 7/10 [====================>.........] - ETA: 17s - loss: 0.6909 - acc: 0.7090"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-3cc265da52d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       validation_steps=10)\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=10,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q6mGSHvbqWV9"
   },
   "outputs": [],
   "source": [
    "def generate_grad_cam(img_tensor, model, class_index, activation_layer):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    -------\n",
    "    img_tensor: resnet50 모델의 이미지 전처리를 통한 image tensor\n",
    "    model: pretrained resnet50 모델 (include_top=True)\n",
    "    class_index: 이미지넷 정답 레이블\n",
    "    activation_layer: 시각화하려는 레이어 이름\n",
    "\n",
    "    return:\n",
    "    grad_cam: grad_cam 히트맵\n",
    "    \"\"\"\n",
    "    inp = model.input\n",
    "    y_c = model.output.op.inputs[0][0, class_index]\n",
    "    A_k = model.get_layer(activation_layer).output\n",
    "    \n",
    "    ## 이미지 텐서를 입력해서\n",
    "    ## 해당 액티베이션 레이어의 아웃풋(a_k)과\n",
    "    ## 소프트맥스 함수 인풋의 a_k에 대한 gradient를 구한다.\n",
    "    get_output = K.function([inp], [A_k, K.gradients(y_c, A_k)[0], model.output])\n",
    "    [conv_output, grad_val, model_output] = get_output([img_tensor])\n",
    "\n",
    "    ## 배치 사이즈가 1이므로 배치 차원을 없앤다.\n",
    "    conv_output = conv_output[0]\n",
    "    grad_val = grad_val[0]\n",
    "    \n",
    "    ## 구한 gradient를 픽셀 가로세로로 평균내서 a^c_k를 구한다.\n",
    "    weights = np.mean(grad_val, axis=(0, 1))\n",
    "    \n",
    "    ## 추출한 conv_output에 weight를 곱하고 합하여 grad_cam을 얻는다.\n",
    "    grad_cam = np.zeros(dtype=np.float32, shape=conv_output.shape[0:2])\n",
    "    for k, w in enumerate(weights):\n",
    "        grad_cam += w * conv_output[:, :, k]\n",
    "    \n",
    "    grad_cam = cv2.resize(grad_cam, (224, 224))\n",
    "\n",
    "    ## ReLU를 씌워 음수를 0으로 만든다.\n",
    "    grad_cam = np.maximum(grad_cam, 0)\n",
    "\n",
    "    grad_cam = grad_cam / grad_cam.max()\n",
    "    return grad_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3h6M1U8dwFnL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vUDYv1N9qWV_",
    "outputId": "bc0fae53-6eda-4ac2-c4eb-b904ee998d5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25606b55d88>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "plt.matshow(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VP77aa_wqWWD"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "\n",
    "cv2.imwrite('elephant_cam.jpg', superimposed_img)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Resnet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
